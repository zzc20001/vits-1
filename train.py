import os
import json
import argparse
import itertools
import math
import logging
import torch
from torch import nn, optim
from torch.nn import functional as F
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import torch.multiprocessing as mp
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.cuda.amp import autocast, GradScaler

# å¯¼å…¥VITSæ ¸å¿ƒæ¨¡å—
import commons
import utils
from data_utils import (
  TextAudioLoader,
  TextAudioCollate
)
from models import (
  SynthesizerTrn,
  MultiPeriodDiscriminator,
)
from losses import (
  generator_loss,
  discriminator_loss,
  feature_loss,
  kl_loss
)
from mel_processing import mel_spectrogram_torch, spec_to_mel_torch, spectrogram_torch
from text.symbols import symbols

# ===================== å…¨å±€é…ç½®ï¼ˆé€‚é…4GBæ˜¾å­˜ï¼‰ =====================
torch.backends.cudnn.benchmark = True
global_step = 0

# ä½ç§©å¾®è°ƒé…ç½®
LOW_RANK_CKPT_PATH = "./init_low_rank_model.pth"  # ä½ç§©æƒé‡è·¯å¾„
FREEZE_NON_LOW_RANK = True                        # å†»ç»“éä½ç§©å±‚
EXPECTED_LOW_RANK_PARAMS = 54                     # é¢„æœŸä½ç§©å‚æ•°æ•°é‡

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ===================== å·¥å…·å‡½æ•° =====================
def hparams_to_dict(hparams_obj):
    """å°†HParamså¯¹è±¡è½¬ä¸ºå­—å…¸"""
    if hasattr(hparams_obj, '__dict__'):
        return hparams_obj.__dict__.copy()
    return {}

def freeze_non_low_rank_params(net_g):
    """å†»ç»“éä½ç§©å±‚å‚æ•°ï¼ˆä»…ä¿ç•™W1/W2å¯è®­ç»ƒï¼‰"""
    frozen_count = 0
    trainable_count = 0
    for name, param in net_g.named_parameters():
        # ä»…ä¿ç•™ä½ç§©å±‚å‚æ•°å¯è®­ç»ƒ
        if (
            "enc_p.encoder.attn_layers" in name
            and ("conv_q" in name or "conv_k" in name or "conv_v" in name)
            and ("W1" in name or "W2" in name)
        ):
            param.requires_grad = True
            trainable_count += 1
            logger.info(f"âœ… å¯è®­ç»ƒå‚æ•°ï¼š{name} | å½¢çŠ¶ï¼š{param.shape}")
        else:
            param.requires_grad = False
            frozen_count += 1
    
    logger.info(f"\nğŸ“Š å‚æ•°å†»ç»“ç»Ÿè®¡ï¼š")
    logger.info(f"   å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼š{trainable_count}ï¼ˆé¢„æœŸ{EXPECTED_LOW_RANK_PARAMS}ï¼‰")
    logger.info(f"   å†»ç»“å‚æ•°æ•°é‡ï¼š{frozen_count}")
    if trainable_count != EXPECTED_LOW_RANK_PARAMS:
        logger.warning(f"âš ï¸  å¯è®­ç»ƒå‚æ•°æ•°é‡ä¸ç¬¦ï¼é¢„æœŸ{EXPECTED_LOW_RANK_PARAMS}ï¼Œå®é™…{trainable_count}")
    
    return trainable_count

def evaluate(hps, generator, eval_loader, writer_eval, global_step):
    """è½»é‡åŒ–éªŒè¯ï¼ˆé€‚é…4GBæ˜¾å­˜ï¼‰"""
    generator.eval()
    device = next(generator.parameters()).device
    with torch.no_grad():
        # ä»…å–ç¬¬ä¸€ä¸ªæ ·æœ¬éªŒè¯ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
        for batch in eval_loader:
            x, x_lengths, spec, spec_lengths, y, y_lengths = batch
            x = x[:1].to(device)
            x_lengths = x_lengths[:1].to(device)
            spec = spec[:1].to(device)
            spec_lengths = spec_lengths[:1].to(device)
            y = y[:1].to(device)
            y_lengths = y_lengths[:1].to(device)
            break
        
        # æ¨ç†ï¼ˆå‡å°æœ€å¤§é•¿åº¦ï¼‰
        y_hat, attn, mask, *_ = generator.infer(x, x_lengths, max_len=500)
        y_hat_lengths = mask.sum([1,2]).long() * hps.data.hop_length

        # è®¡ç®—Melè°±å›¾
        mel = spec_to_mel_torch(
            spec, 
            hps.data.filter_length, 
            hps.data.n_mel_channels, 
            hps.data.sampling_rate,
            hps.data.mel_fmin, 
            hps.data.mel_fmax)
        y_hat_mel = mel_spectrogram_torch(
            y_hat.squeeze(1).float(),
            hps.data.filter_length,
            hps.data.n_mel_channels,
            hps.data.sampling_rate,
            hps.data.hop_length,
            hps.data.win_length,
            hps.data.mel_fmin,
            hps.data.mel_fmax
        )

    # è®°å½•ç»“æœ
    image_dict = {
        "eval/mel_gen": utils.plot_spectrogram_to_numpy(y_hat_mel[0].cpu().numpy()),
        "eval/mel_gt": utils.plot_spectrogram_to_numpy(mel[0].cpu().numpy())
    }
    audio_dict = {
        "eval/audio_gen": y_hat[0,:,:y_hat_lengths[0]],
        "eval/audio_gt": y[0,:,:y_lengths[0]]
    }
    utils.summarize(
        writer=writer_eval,
        global_step=global_step,
        images=image_dict,
        audios=audio_dict,
        audio_sampling_rate=hps.data.sampling_rate
    )
    generator.train()

# ===================== ä¸»è®­ç»ƒå‡½æ•°ï¼ˆå•è¿›ç¨‹ï¼Œé€‚é…4GBæ˜¾å­˜ï¼‰ =====================
def main():
    """å•è¿›ç¨‹å•GPUè®­ç»ƒï¼ˆç¦ç”¨åˆ†å¸ƒå¼ï¼Œé€‚é…4GBæ˜¾å­˜ï¼‰"""
    assert torch.cuda.is_available(), "CPU training is not allowed."

    # åŠ è½½é…ç½®
    hps = utils.get_hparams()
    
    # 4GBæ˜¾å­˜å¼ºåˆ¶ä¼˜åŒ–é…ç½®
    hps.train.batch_size = 1               # æœ€å°æ‰¹æ¬¡
    hps.train.fp16_run = True              # å¼€å¯FP16
    hps.train.segment_size = 4096          # æœ€å°éŸ³é¢‘ç‰‡æ®µé•¿åº¦
    hps.train.log_interval = 5             # æ›´é¢‘ç¹çš„æ—¥å¿—è¾“å‡º
    hps.train.eval_interval = 50           # éªŒè¯é—´éš”
    hps.train.epochs = 50                  # ä½ç§©å¾®è°ƒè½®æ¬¡

    # è®¾å¤‡åˆå§‹åŒ–
    device = torch.device("cuda:0")
    torch.manual_seed(hps.train.seed)
    torch.cuda.set_device(device)
    logger.info(f"===== VITSä½ç§©å¾®è°ƒè®­ç»ƒï¼ˆ4GBæ˜¾å­˜ä¼˜åŒ–ï¼‰ =====")
    logger.info(f"è®¾å¤‡ï¼š{device} | æ‰¹æ¬¡å¤§å°ï¼š{hps.train.batch_size} | FP16ï¼š{hps.train.fp16_run}")
    logger.info(f"éŸ³é¢‘ç‰‡æ®µé•¿åº¦ï¼š{hps.train.segment_size} | è®­ç»ƒè½®æ¬¡ï¼š{hps.train.epochs}")

    # æ—¥å¿—å’ŒTensorBoard
    logger.info(f"æ¨¡å‹ä¿å­˜è·¯å¾„ï¼š{hps.model_dir}")
    utils.check_git_hash(hps.model_dir)
    writer = SummaryWriter(log_dir=hps.model_dir)
    writer_eval = SummaryWriter(log_dir=os.path.join(hps.model_dir, "eval"))

    # ===================== 1. æ•°æ®åŠ è½½ï¼ˆå•è¿›ç¨‹ï¼Œç¦ç”¨workerï¼‰ =====================
# è®­ç»ƒä»£ç ä¸­mainå‡½æ•°é‡Œçš„DataLoaderæ„å»ºéƒ¨åˆ†ï¼ˆæ›¿æ¢åŸæœ‰ï¼‰
# ===================== 1. æ•°æ®åŠ è½½ï¼ˆå•è¿›ç¨‹ï¼Œç¦ç”¨workerï¼‰ =====================
# è®­ç»ƒé›†
    train_dataset = TextAudioLoader(hps.data.training_files, hps)
# å®ä¾‹åŒ–Collateç±»ï¼ˆè‡ªåŠ¨é€‚é…ç»“æ„ï¼‰
    collate_fn = TextAudioCollate(return_ids=False)
    train_loader = DataLoader(
        train_dataset,
        batch_size=hps.train.batch_size,
        shuffle=True,
        num_workers=0,          # ç¦ç”¨workerè¿›ç¨‹ï¼ˆå…³é”®ä¿®å¤ï¼‰
        pin_memory=False,       # å…³é—­pin_memory
        collate_fn=collate_fn,
        drop_last=True
    )

# éªŒè¯é›†
    eval_dataset = TextAudioLoader(hps.data.validation_files, hps)
    eval_loader = DataLoader(
        eval_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=0,
        pin_memory=False,
        collate_fn=collate_fn,
        drop_last=False
    )

    # ===================== 2. æ¨¡å‹æ„å»º + ä½ç§©Encoderæ›¿æ¢ =====================
    logger.info("æ„å»ºSynthesizerTrnæ¨¡å‹...")
    net_g = SynthesizerTrn(
        len(symbols),
        hps.data.filter_length // 2 + 1,
        hps.train.segment_size // hps.data.hop_length,
        **hps.model
    ).to(device)

    # æ›¿æ¢ä¸ºä½ç§©Encoderï¼ˆæ ¸å¿ƒï¼‰
    logger.info("æ›¿æ¢enc_p.encoderä¸ºä½ç§©ç‰ˆæœ¬...")
    from attentions import Encoder as LowRankEncoder
    model_cfg = hparams_to_dict(hps.model)
    encoder_config = {
        "hidden_channels": model_cfg.get("hidden_channels", 192),
        "filter_channels": model_cfg.get("filter_channels", 768),
        "n_heads": model_cfg.get("n_heads", 2),
        "n_layers": model_cfg.get("n_layers", 6),
        "kernel_size": model_cfg.get("kernel_size", 3),
        "p_dropout": model_cfg.get("p_dropout", 0.1),
        "window_size": model_cfg.get("window_size", 4)
    }
    low_rank_encoder = LowRankEncoder(**encoder_config).to(device)
    net_g.enc_p.encoder = low_rank_encoder
    logger.info("âœ… ä½ç§©Encoderæ›¿æ¢å®Œæˆ")

    # åŠ è½½ä½ç§©æƒé‡
    if os.path.exists(LOW_RANK_CKPT_PATH):
        logger.info(f"åŠ è½½ä½ç§©æƒé‡ï¼š{LOW_RANK_CKPT_PATH}")
        low_rank_ckpt = torch.load(
            LOW_RANK_CKPT_PATH,
            map_location=device,
            weights_only=True
        )
        # ä¸¥æ ¼=Falseï¼Œå¿½ç•¥ä¸åŒ¹é…çš„å‚æ•°
        net_g.load_state_dict(low_rank_ckpt.get("net_g", low_rank_ckpt), strict=False)
        logger.info("âœ… ä½ç§©æƒé‡åŠ è½½æˆåŠŸ")
    else:
        raise FileNotFoundError(f"âŒ ä½ç§©æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{LOW_RANK_CKPT_PATH}")

    # æ„å»ºåˆ¤åˆ«å™¨ï¼ˆå†»ç»“ï¼Œå‡å°‘æ˜¾å­˜å ç”¨ï¼‰
    logger.info("æ„å»ºåˆ¤åˆ«å™¨å¹¶å†»ç»“...")
    net_d = MultiPeriodDiscriminator(hps.model.use_spectral_norm).to(device)
    for param in net_d.parameters():
        param.requires_grad = False
    logger.info("âœ… åˆ¤åˆ«å™¨å·²å†»ç»“")

    # ===================== 3. å‚æ•°å†»ç»“ + ä¼˜åŒ–å™¨é…ç½® =====================
    # å†»ç»“éä½ç§©å±‚
    if FREEZE_NON_LOW_RANK:
        logger.info("å†»ç»“éä½ç§©å±‚å‚æ•°...")
        trainable_count = freeze_non_low_rank_params(net_g)
        if trainable_count == 0:
            raise ValueError("âŒ æ— å¯ç”¨çš„å¯è®­ç»ƒå‚æ•°ï¼è¯·æ£€æŸ¥ä½ç§©å±‚å®šä¹‰")

    # ä»…ä¼˜åŒ–å¯è®­ç»ƒå‚æ•°ï¼ˆä½ç§©å±‚ï¼‰
    optim_g = torch.optim.AdamW(
        filter(lambda p: p.requires_grad, net_g.parameters()),
        lr=1e-5,                # ä½ç§©å¾®è°ƒå°å­¦ä¹ ç‡
        betas=hps.train.betas,
        eps=hps.train.eps,
        weight_decay=1e-6       # å°æƒé‡è¡°å‡
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆæ…¢è¡°å‡ï¼‰
    scheduler_g = torch.optim.lr_scheduler.ExponentialLR(
        optim_g,
        gamma=0.99,             # æ›´æ…¢çš„è¡°å‡ç‡
        last_epoch=-1
    )

    # FP16æ¢¯åº¦ç¼©æ”¾ï¼ˆæ ¸å¿ƒæ˜¾å­˜ä¼˜åŒ–ï¼‰
    scaler = GradScaler(enabled=hps.train.fp16_run)

    # ===================== 4. æ ¸å¿ƒè®­ç»ƒå¾ªç¯ =====================
    global global_step
    global_step = 0
    total_loss = 0.0

    logger.info("å¼€å§‹ä½ç§©å¾®è°ƒè®­ç»ƒ...")
    for epoch in range(1, hps.train.epochs + 1):
        logger.info(f"\n===== Epoch {epoch}/{hps.train.epochs} =====")
        net_g.train()
        net_d.train()

        for batch_idx, batch in enumerate(train_loader):
            # æ•°æ®è§£åŒ…å¹¶ç§»åˆ°GPU
            x, x_lengths, spec, spec_lengths, y, y_lengths = batch
            x = x.to(device, non_blocking=True)
            x_lengths = x_lengths.to(device, non_blocking=True)
            spec = spec.to(device, non_blocking=True)
            spec_lengths = spec_lengths.to(device, non_blocking=True)
            y = y.to(device, non_blocking=True)
            y_lengths = y_lengths.to(device, non_blocking=True)

            # FP16å‰å‘ä¼ æ’­
            with autocast(enabled=hps.train.fp16_run):
                # ç”Ÿæˆå™¨å‰å‘è®¡ç®—
                y_hat, l_length, attn, ids_slice, x_mask, z_mask, \
                (z, z_p, m_p, logs_p, m_q, logs_q) = net_g(x, x_lengths, spec, spec_lengths)

                # è®¡ç®—Melè°±å›¾
                mel = spec_to_mel_torch(
                    spec, 
                    hps.data.filter_length, 
                    hps.data.n_mel_channels, 
                    hps.data.sampling_rate,
                    hps.data.mel_fmin, 
                    hps.data.mel_fmax)
                y_mel = commons.slice_segments(
                    mel, ids_slice, hps.train.segment_size // hps.data.hop_length)
                y_hat_mel = mel_spectrogram_torch(
                    y_hat.squeeze(1), 
                    hps.data.filter_length, 
                    hps.data.n_mel_channels, 
                    hps.data.sampling_rate, 
                    hps.data.hop_length, 
                    hps.data.win_length, 
                    hps.data.mel_fmin, 
                    hps.data.mel_fmax
                )

                # éŸ³é¢‘åˆ‡ç‰‡
                y = commons.slice_segments(y, ids_slice * hps.data.hop_length, hps.train.segment_size)

                # åˆ¤åˆ«å™¨è®¡ç®—ï¼ˆä»…å‰å‘ï¼Œå†»ç»“å‚æ•°ï¼‰
                y_d_hat_r, y_d_hat_g, _, _ = net_d(y, y_hat.detach())
                loss_disc, losses_disc_r, losses_disc_g = discriminator_loss(y_d_hat_r, y_d_hat_g)

                # ç”Ÿæˆå™¨æŸå¤±è®¡ç®—
                y_d_hat_r, y_d_hat_g, fmap_r, fmap_g = net_d(y, y_hat)
                loss_dur = torch.sum(l_length.float())
                loss_mel = F.l1_loss(y_mel, y_hat_mel) * hps.train.c_mel
                loss_kl = kl_loss(z_p, logs_q, m_p, logs_p, z_mask) * hps.train.c_kl
                loss_fm = feature_loss(fmap_r, fmap_g)
                loss_gen, losses_gen = generator_loss(y_d_hat_g)
                
                # æ€»æŸå¤±
                loss_gen_all = loss_gen + loss_fm + loss_mel + loss_dur + loss_kl

            # åå‘ä¼ æ’­
            optim_g.zero_grad()
            scaler.scale(loss_gen_all).backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢çˆ†ç‚¸ï¼‰
            scaler.unscale_(optim_g)
            grad_norm_g = commons.clip_grad_value_(net_g.parameters(), 1.0)
            
            # æ›´æ–°ä¼˜åŒ–å™¨
            scaler.step(optim_g)
            scaler.update()

            # æŸå¤±ç´¯è®¡
            total_loss += loss_gen_all.item()
            global_step += 1

            # ===================== æ—¥å¿—è¾“å‡º & éªŒè¯ & ä¿å­˜ =====================
            if global_step % hps.train.log_interval == 0:
                # è®¡ç®—å¹³å‡æŸå¤±
                avg_loss = total_loss / hps.train.log_interval
                lr = optim_g.param_groups[0]['lr']
                
                # æ‰“å°æ—¥å¿—
                logger.info(f"Batch {batch_idx} | Loss: {avg_loss:.4f} | LR: {lr:.6f} | Grad Norm: {grad_norm_g:.4f}")
                
                # TensorBoardè®°å½•
                scalar_dict = {
                    "loss/g/total": avg_loss,
                    "loss/g/mel": loss_mel.item(),
                    "loss/g/kl": loss_kl.item(),
                    "loss/g/fm": loss_fm.item(),
                    "learning_rate": lr,
                    "grad_norm_g": grad_norm_g
                }
                utils.summarize(
                    writer=writer,
                    global_step=global_step,
                    scalars=scalar_dict,
                    images={
                        "mel/gt": utils.plot_spectrogram_to_numpy(y_mel[0].data.cpu().numpy()),
                        "mel/gen": utils.plot_spectrogram_to_numpy(y_hat_mel[0].data.cpu().numpy()),
                        "attn": utils.plot_alignment_to_numpy(attn[0,0].data.cpu().numpy())
                    }
                )
                total_loss = 0.0

            # éªŒè¯å’Œä¿å­˜æƒé‡
            if global_step % hps.train.eval_interval == 0:
                evaluate(hps, net_g, eval_loader, writer_eval, global_step)
                save_path = os.path.join(hps.model_dir, f"G_lowrank_{global_step}.pth")
                utils.save_checkpoint(
                    net_g, optim_g, lr, epoch, save_path
                )
                logger.info(f"âœ… æƒé‡å·²ä¿å­˜ï¼š{save_path}")

        # å­¦ä¹ ç‡è¡°å‡
        scheduler_g.step()
        logger.info(f"Epoch {epoch} å®Œæˆ | å½“å‰å­¦ä¹ ç‡ï¼š{optim_g.param_groups[0]['lr']:.6f}")

    # ===================== è®­ç»ƒå®Œæˆ =====================
    final_path = os.path.join(hps.model_dir, "G_lowrank_final.pth")
    utils.save_checkpoint(
        net_g, optim_g, optim_g.param_groups[0]['lr'], hps.train.epochs, final_path
    )
    logger.info(f"ğŸ‰ ä½ç§©å¾®è°ƒè®­ç»ƒå®Œæˆï¼æœ€ç»ˆæƒé‡ä¿å­˜ï¼š{final_path}")

# ===================== å…¥å£å‡½æ•° =====================
if __name__ == "__main__":
    main()